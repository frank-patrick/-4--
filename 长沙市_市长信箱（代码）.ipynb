{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import re \n",
    "from bs4 import BeautifulSoup \n",
    "import bs4 \n",
    "import pandas as pd \n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHtmlUrl(ulist, htmls):   # 得到全部信件链接,并获得信件类型    \n",
    "    for html in htmls:        \n",
    "        soup = BeautifulSoup(html, 'html.parser')        \n",
    "        for link in soup.find_all('a'):            \n",
    "            links = link.get('href')            \n",
    "            if re.match('viewPublic.jsp\\?id=.*?&cxm=',                        \n",
    "                        str(links)):                \n",
    "                ulist.append('http://wlwz.changsha.gov.cn/webapp/cs/email/' + \n",
    "                             links) \n",
    "        # 利用beautifulsoup提取表格中指定列属性       \n",
    "        trs = soup.find('div', class_='information_table').find_all('tr')       \n",
    "        for tr in trs:            \n",
    "            for td in tr.find_all('td')[2:3]:                \n",
    "                Type.append(td.getText())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHtmlText(urls):          # 爬取页面内容    \n",
    "    texts = []    \n",
    "    i = 1    \n",
    "    for url in urls:        \n",
    "        try:            \n",
    "            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36'}           \n",
    "            r = requests.get(url, headers=headers, timeout=100)            \n",
    "            r.raise_for_status()            \n",
    "            r.encoding = r.apparent_encoding            \n",
    "            texts.append(r.text)            \n",
    "            print(i)            \n",
    "            i += 1        \n",
    "        except:            \n",
    "            print('链接失败')    \n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def workdayss(start, end):    # 计算两个日期间工作日/记得检查数据是否存在巨大差距，比方s：2015，e：1900    \n",
    "    # 记得需要删除标题行    \n",
    "    from datetime import datetime,timedelta    \n",
    "    from chinese_calendar import is_workday\n",
    "    print(start)\n",
    "    print(end)\n",
    "    if start > end:        \n",
    "        start,end = end,start    \n",
    "    counts = 0    \n",
    "    while True:        \n",
    "        if start > end:            \n",
    "            break        \n",
    "        if is_workday(start):            \n",
    "            counts += 1        \n",
    "        start += timedelta(days=1)    \n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_field(article):                    # 领域识别功能    \n",
    "        import jieba    \n",
    "        import csv    \n",
    "        fields = {}    \n",
    "        fieldName = []    # 读取领域库    \n",
    "        with open('C:\\\\Users\\\\76595\\\\Desktop\\\\信件领域.txt','r', encoding='utf-8' ) as f:        \n",
    "            for line in f.readlines():            \n",
    "                data = line.replace('\\n','').split('；')     # 注意中英文            \n",
    "                fieldName.append(data[0])            \n",
    "                for keyword in data[1:]:                \n",
    "                    fields[keyword] = data[0]    \n",
    "        frequency = {name: 0 for name in fieldName}\n",
    "        \n",
    "        # 文本分词    \n",
    "        sw = pd.read_csv(r'C:\\Users\\76595\\Desktop\\停用词.txt',                     \n",
    "                         encoding='utf-8',sep='\\n',quoting=csv.QUOTE_NONE,header=None)    # 将文档分词并去除停用词    \n",
    "        stop_list = sw[0].tolist()    \n",
    "        word_cut = [i for i in jieba.lcut(article) if i not in stop_list]   \n",
    "        # 去除无关字符串    \n",
    "        while True:        \n",
    "            if '\\n' in line:            \n",
    "                line.remove('\\n')        \n",
    "            elif '\\t' in line:            \n",
    "                line.remove('\\t')        \n",
    "            elif ' ' in line:           \n",
    "                line.remove(' ')        \n",
    "            elif '\\r' in line:            \n",
    "                line.remove('\\r')        \n",
    "            elif '\\r\\n' in line:            \n",
    "                line.remove('\\r\\n')        \n",
    "            elif '\\xa0' in line:            \n",
    "                line.remove('\\xa0')        \n",
    "            else:            \n",
    "                break    \n",
    "        words=[]    \n",
    "        for content in word_cut:        \n",
    "            words.append(content)    \n",
    "        words = list(set(words))        # 去除重复元素\n",
    "        # 统计、排序    \n",
    "        for word in words:        \n",
    "            try:            \n",
    "                frequency[fields[word]] += 1        \n",
    "            except Exception:            \n",
    "                pass   \n",
    "        result = sorted(frequency.items(), key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "        if result[0][1] == 0:        \n",
    "            return '其他事件'    \n",
    "        else:        \n",
    "            return result[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillList(htmls):    \n",
    "    from datetime import datetime       # 用于提取信件归属年份    \n",
    "    i = 1    \n",
    "    for html in htmls:        \n",
    "        print(':', i)        \n",
    "        i += 1        \n",
    "        soup = BeautifulSoup(html, 'html.parser')        \n",
    "        for tag in soup.find_all('div', class_='incoming_letter'):            \n",
    "            title = tag.find('div', class_='mailbox_title').get_text()      # 标题  \n",
    "            try:                \n",
    "                appraise = ''                \n",
    "                appraise = tag.find('span', class_='dissatisfied').get_text()                \n",
    "                appraise = appraise.lstrip('满意度：')   # 删掉开头的 满意度： 字段                \n",
    "                appraise = appraise.strip()             # 删去'\\n', '\\r',  '\\t',  ' '            \n",
    "            except:                \n",
    "                print(appraise)            \n",
    "            contents = tag.find('div', class_='mailbox_reader').get_text()  # 文字内容            \n",
    "            name = tag.findAll('span', class_='human')            \n",
    "            try:                \n",
    "                depname = ''                \n",
    "                depname = name[1].contents[0]              # 回复部门            \n",
    "            except:                \n",
    "                print(depname)            \n",
    "            time = tag.findAll('span', class_='time')            \n",
    "            try:                \n",
    "                begintime = str(time[0].contents[0])                \n",
    "                endtime = str(time[1].contents[0])            \n",
    "            except:                \n",
    "                begintime = '2000-01-01'                \n",
    "                endtime = '2000-01-02'                \n",
    "                print('匹配不到时间标签')\n",
    "            try:                              # 将字符型转换成Date;预防爬取内容里面出现多种格式                \n",
    "                response = 0                                    # 初始化                \n",
    "                year = 0                                        # 初始化                \n",
    "                if  re.search(r'(\\d{4}-\\d{1,2}-\\d{1,2}\\s\\d{1,2}:\\d{1,2}:\\d{1,2})', begintime) != None:                   \n",
    "                    begintime =datetime.strptime(begintime,'%Y-%m-%d %H:%M:%S')                   \n",
    "                else:                    \n",
    "                    begintime = datetime.strptime(begintime, '%Y-%m-%d').date()                \n",
    "                if  re.search(r'(\\d{4}-\\d{1,2}-\\d{1,2}\\s\\d{1,2}:\\d{1,2}:\\d{1,2})', endtime) != None:                    \n",
    "                    endtime = datetime.strptime(endtime,'%Y-%m-%d %H:%M:%S') \n",
    "                else:                    \n",
    "                    endtime = datetime.strptime(endtime, '%Y-%m-%d').date()               \n",
    "                year = endtime.year # 信件归属年份    \n",
    "                response = workdayss(begintime, endtime)    # 政府回应时长\n",
    "\n",
    "            except:                \n",
    "                print('时间问题')                \n",
    "                print(title)                            \n",
    "\n",
    "            try:                                           # 领域识别                \n",
    "                 field = ''                \n",
    "                 field = get_field(contents)            \n",
    "            except:                \n",
    "                 print('无法识别领域')\n",
    "           \n",
    "        # 写入列表            \n",
    "            Title.append(title)            \n",
    "            DepName.append(depname)            \n",
    "            BeginTime.append(begintime)            \n",
    "            EndTime.append(endtime)            \n",
    "            Appraise.append(appraise)            \n",
    "            Year.append(year)            \n",
    "            Response.append(response)            \n",
    "            Field.append(field)           \n",
    "            Contents.append(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      ": 1\n",
      "时间问题\n",
      "长沙县什么时候撤县设区？相关工作已经进行到哪一步了？（请转长沙市民政局）\n",
      ": 2\n",
      "时间问题\n",
      "关于房产证加名字咨询\n",
      ": 3\n",
      "时间问题\n",
      "强烈建议长沙火车站（老站）与锦泰广场站（城际站）之间增加可双向互通的旅客通道\n",
      ": 4\n",
      "时间问题\n",
      "城际铁路河西到株洲段不合理的改进建议\n",
      ": 5\n",
      "时间问题\n",
      "夜景亮化工程\n",
      ": 6\n",
      "时间问题\n",
      "美的翰城精装修检查已经过了一年多，竟然检查结果仍未公布\n",
      ": 7\n",
      "时间问题\n",
      "个大医院停止疫苗接种\n",
      ": 8\n",
      "时间问题\n",
      "我还是有点疑问\n",
      ": 9\n",
      "时间问题\n",
      "2018年11月的全市精装修检查，2020年2月，音讯全无，无疾而终！\n",
      ": 10\n",
      "时间问题\n",
      "长沙市疾病防控中心2\n",
      ": 11\n",
      "时间问题\n",
      "关于长沙市房产限购政策的问题\n",
      ": 12\n",
      "时间问题\n",
      "为什么6号线不到莲花镇？\n",
      ": 13\n",
      "时间问题\n",
      "关于对长沙公交的建议\n",
      ": 14\n",
      "时间问题\n",
      "长沙市企业复工时间早于2月9日\n",
      ": 15\n",
      "时间问题\n",
      "湖南创通互联网通讯企业有限公司与中国石油雷锋大道加油站欺诈消费者\n",
      ": 16\n",
      "时间问题\n",
      "望城区规划局对于中粮鸿云公变配电房未按照规划图建设一事不作为\n",
      ": 17\n",
      "时间问题\n",
      "长沙县梨江社区私自决定隔离时间并限制个人出行\n",
      ": 18\n",
      "时间问题\n",
      "关于长沙市自然资源规划局望城分局违法审批开发商小区规划的问题\n",
      ": 19\n",
      "时间问题\n",
      "小学、初中学位\n",
      ": 20\n",
      "时间问题\n",
      "咨询金山桥街道观音岩片区的发展\n",
      ": 21\n",
      "时间问题\n",
      "望城区农户合法申请宅基地却被长时间无故拖延！\n",
      ": 22\n",
      "时间问题\n",
      "来长沙工作不满1年，小学就读问题\n",
      ": 23\n",
      "时间问题\n",
      "额滴个神的湖南巴士哟\n",
      ": 24\n",
      "时间问题\n",
      "居民区楼房内养鸽子不听劝阻极度扰民\n"
     ]
    }
   ],
   "source": [
    "urls = [    \n",
    "   \"http://wlwz.changsha.gov.cn/webapp/cs/email/index.jsp?orgId=&cflag=1&type=&stype=1&emailList.offset={}&emailList.desc=false\".format(str(12*i))\n",
    "    for i in range(300,2801) \n",
    "]\n",
    "\n",
    "html_a = getHtmlText(urls)\n",
    "catalog = []                              # 存储所有信件页面链接 \n",
    "Type = []                                 # 信件类型 \n",
    "getHtmlUrl(catalog, html_a) \n",
    "Title = [] \n",
    "DepName = [] \n",
    "BeginTime = [] \n",
    "EndTime = [] \n",
    "Appraise = [] \n",
    "Year = [] \n",
    "Response = [] \n",
    "Contents = [] \n",
    "Field = [] \n",
    "html_b = getHtmlText(catalog) \n",
    "fillList(html_b)\n",
    "\n",
    "# 主分析对象 \n",
    "dataframe = pd.DataFrame({'Title':Title,'DepName':DepName, 'Type':Type, 'BeginTime':BeginTime, 'EndTime':EndTime,\n",
    "                          'Appraise': Appraise, 'Year':Year,'Response': Response, 'Field': Field}) \n",
    "dataframe.to_csv('C:\\\\Users\\\\76595\\\\Desktop\\\\长沙市_市长信箱_1.csv',mode='a', encoding='gb18030',index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
